{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '/scratch/szym/introns/noncanonical_introns')\n",
    "\n",
    "import kmeans\n",
    "import random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1637851 1910948 read:  6.31156849861145 seconds, all: 7.870845317840576 seconds\n"
     ]
    }
   ],
   "source": [
    "#head -n 20000 selected_introns.fasta > subset.fasta\n",
    "\n",
    "started = time.time()\n",
    "file = '/scratch/szym/introns/all_introns.fasta'\n",
    "with open(file, \"r\") as handle:\n",
    "    sequences = list(SimpleFastaParser(handle))\n",
    "\n",
    "ended = time.time()\n",
    "types = np.zeros((len(sequences),), dtype=int)\n",
    "for i, s in enumerate(sequences):\n",
    "    #left_anchor = s[1][3:5]\n",
    "    #right_anchor = s[1][-5:-3]\n",
    "    #if left_anchor == 'GT' and right_anchor == 'AG' or left_anchor == 'CT' and right_anchor == 'AC':\n",
    "    class_signature=s[0][-2:]\n",
    "    if class_signature == \"KX\":    \n",
    "        # 0  for conventional intron\n",
    "        types[i] = (0)\n",
    "    else:\n",
    "        # 1 for nonconventional\n",
    "        types[i] = (1)\n",
    "\n",
    "print(sum(types), len(types), \"read: \", ended-started, \"seconds, all:\", time.time()-started, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans clustering of the introns with two different ways of sequence representation, using 4- and 7-mers converted to TF-IDF and different number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   1.   1. ...   1.   1.   1.]\n",
      " [  3.   3.   3. ...   3.   3.   3.]\n",
      " [  1.   1.   1. ...   5.   5.   1.]\n",
      " ...\n",
      " [ 20.  26.  26. ...   0.   0.  29.]\n",
      " [ 11.  26.  26. ...   8.   8.  32.]\n",
      " [100.  43.  43. ...  61.  61.  93.]]\n"
     ]
    }
   ],
   "source": [
    "_,_,seq4, _ = kmeans.preprocess(0, 4, sequences)\n",
    "clusters4 = np.zeros((7, len(sequences)))\n",
    "for x in range(1,8):\n",
    "    n_clusters = 2**x\n",
    "    kmeans_model = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=100, n_init=10, random_state=0, n_jobs=12)\n",
    "    kmeans_model.fit(seq4)\n",
    "    clusters4[x - 1] = kmeans_model.labels_\n",
    "print(clusters4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/cluster/_kmeans.py:793: FutureWarning: 'n_jobs' was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25).\n",
      "  \" removed in 1.0 (renaming of 0.25).\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   1.   1. ...   1.   1.   1.]\n",
      " [  3.   3.   3. ...   3.   3.   3.]\n",
      " [  1.   1.   1. ...   5.   5.   1.]\n",
      " ...\n",
      " [ 20.  26.  26. ...   0.   0.  29.]\n",
      " [ 11.  26.  26. ...   8.   8.  32.]\n",
      " [100.  43.  43. ...  61.  61.  93.]]\n"
     ]
    }
   ],
   "source": [
    "_,_,seq7, _ = kmeans.preprocess(0, 7, sequences)\n",
    "clusters7 = np.zeros((7, len(sequences)))\n",
    "for x in range(1,8):\n",
    "    n_clusters = 2**x\n",
    "    kmeans_model = KMeans(n_clusters=n_clusters, init='k-means++', max_iter=100, n_init=10, random_state=0, n_jobs=12)\n",
    "    kmeans_model.fit(seq4)\n",
    "    clusters7[x - 1] = kmeans_model.labels_\n",
    "print(clusters7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_cluster(clusters, n_of_clusters, true_classes):\n",
    "    clus_dict = dict([(x, [0, 0]) for x in range(n_of_clusters)])\n",
    "    for i, x in enumerate(clusters):\n",
    "        true_type = types[i]\n",
    "        clus_dict[int(x)][true_type] += 1    \n",
    "    \n",
    "    results = [[], []]\n",
    "    for i, x in enumerate(types):\n",
    "        cluster = clusters[i]\n",
    "        res = clus_dict[cluster][x] / sum(clus_dict[cluster])\n",
    "        results[int(x)].append(res)\n",
    "    print('conv: ')\n",
    "    print(sum(results[0]) / len(results[0]))\n",
    "    print('nonconv: ')\n",
    "    print(sum(results[1]) / len(results[1]))\n",
    "    return clus_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Each clustering is evaluated by measuring homogeneity of the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word length: 4, number of clusters: 2\n",
      "conv: \n",
      "0.327519030929496\n",
      "nonconv: \n",
      "0.6748827357661099\n",
      "\n",
      "\n",
      "Word length: 4, number of clusters: 4\n",
      "conv: \n",
      "0.32790181655515566\n",
      "nonconv: \n",
      "0.6750677970854801\n",
      "\n",
      "\n",
      "Word length: 4, number of clusters: 8\n",
      "conv: \n",
      "0.33194712671173565\n",
      "nonconv: \n",
      "0.6770235404173909\n",
      "\n",
      "\n",
      "Word length: 4, number of clusters: 16\n",
      "conv: \n",
      "0.35241632118945776\n",
      "nonconv: \n",
      "0.6869195654586138\n",
      "\n",
      "\n",
      "Word length: 4, number of clusters: 32\n",
      "conv: \n",
      "0.3638433227023758\n",
      "nonconv: \n",
      "0.6924440570667593\n",
      "\n",
      "\n",
      "Word length: 4, number of clusters: 64\n",
      "conv: \n",
      "0.37339158179982307\n",
      "nonconv: \n",
      "0.6970602529425365\n",
      "\n",
      "\n",
      "Word length: 4, number of clusters: 128\n",
      "conv: \n",
      "0.40776065177765697\n",
      "nonconv: \n",
      "0.7136763038337576\n",
      "\n",
      "\n",
      "Word length: 7, number of clusters: 2\n",
      "conv: \n",
      "0.327519030929496\n",
      "nonconv: \n",
      "0.6748827357661099\n",
      "\n",
      "\n",
      "Word length: 7, number of clusters: 4\n",
      "conv: \n",
      "0.32790181655515566\n",
      "nonconv: \n",
      "0.6750677970854801\n",
      "\n",
      "\n",
      "Word length: 7, number of clusters: 8\n",
      "conv: \n",
      "0.33194712671173565\n",
      "nonconv: \n",
      "0.6770235404173909\n",
      "\n",
      "\n",
      "Word length: 7, number of clusters: 16\n",
      "conv: \n",
      "0.35241632118945776\n",
      "nonconv: \n",
      "0.6869195654586138\n",
      "\n",
      "\n",
      "Word length: 7, number of clusters: 32\n",
      "conv: \n",
      "0.3638433227023758\n",
      "nonconv: \n",
      "0.6924440570667593\n",
      "\n",
      "\n",
      "Word length: 7, number of clusters: 64\n",
      "conv: \n",
      "0.37339158179982307\n",
      "nonconv: \n",
      "0.6970602529425365\n",
      "\n",
      "\n",
      "Word length: 7, number of clusters: 128\n",
      "conv: \n",
      "0.40776065177765697\n",
      "nonconv: \n",
      "0.7136763038337576\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in range(1,8):\n",
    "    n_of_clusters =  2**x\n",
    "    print('Word length: 4, number of clusters: %d' % (n_of_clusters))\n",
    "    assess_cluster(clusters4[x-1], n_of_clusters, types)\n",
    "    print('\\n')\n",
    "\n",
    "for x in range(1,8):\n",
    "    n_of_clusters =  2**x\n",
    "    print('Word length: 7, number of clusters: %d' % (n_of_clusters))\n",
    "    assess_cluster(clusters7[x-1], n_of_clusters, types)\n",
    "    print('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then the sequences are classified by random forests. K-mers ranging from 4 to 11 are used for representation and for each length the classification is done twice - using whole sequences or without the junctions that were used to divide them into conventional or nonconventional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "len of ogligonucleotides:  4\n",
      "uncut sequences: \n",
      "0.8581666666666665\n",
      "conventional splices cut: \n",
      "0.8604666666666667\n",
      "\n",
      "len of ogligonucleotides:  5\n",
      "uncut sequences: \n",
      "0.8584333333333335\n",
      "conventional splices cut: \n",
      "0.8606\n"
     ]
    }
   ],
   "source": [
    "#file = 'data/good_introns50+3.fasta'\n",
    "#with open(file, \"r\") as handle:\n",
    "#    sequences = list(SimpleFastaParser(handle))\n",
    "\n",
    "#types = []\n",
    "#for s in sequences:\n",
    "#    left_anchor = s[1][3:5]\n",
    "#    right_anchor = s[1][-5:-3]\n",
    "#    if left_anchor == 'GT' and right_anchor == 'AG' or left_anchor == 'CT' and right_anchor == 'AC':\n",
    "#        types.append(0)\n",
    "#    else:\n",
    "#        types.append(1)\n",
    "\n",
    "\n",
    "for n in range(4, 6):\n",
    "    print('\\nlen of ogligonucleotides: ', n)\n",
    "    for cut in range(2):\n",
    "        if cut == 0:\n",
    "            print('uncut sequences: ')\n",
    "        if cut == 1:\n",
    "            print('conventional splices cut: ')\n",
    "        data = random_forest.preprocess(cut, n, sequences)\n",
    "        acc = random_forest.forest(10, data, types)\n",
    "        print(str(acc))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "2074.7414848804474 seconds\n",
      "GTGCGTT TGCGTTG GCGTTGC CGTTGCC GTTGCCT TTGCCTG TGCCTGT GCCTGTG CCTGTGT CTGTGTG TGTGTGA GTGTGAC TGTGACC GTGACCC TGACCCC GACCCCA ACCCCAA CCCCAAT CCCAATT CCAATTC CAATTCC AATTCCA ATTCCAG TTCCAGA TCCAGAT CCAGATT CAGATTT AGATTTT GATTTTG ATTTTGG TTTTGGG TTTGGGA TTGGGAA TGGGAAT GGGAATG GGAATGC GAATGCC AATGCCA ATGCCAA TGCCAAC GCCAACG CCAACGT CAACGTA AACGTAA ACGTAAT CGTAATG GTAATGC TAATGCC AATGCCA ATGCCAA TGCCAAC GCCAACA CCAACAT CAACATG AACATGG ACATGGG CATGGGA ATGGGAA TGGGAAA GGGAAAA GGAAAAA GAAAAAA AAAAAAT AAAAATC AAAATCA AAATCAC AATCACC ATCACCC TCACCCT CACCCTT ACCCTTG CCCTTGA CCTTGAA CTTGAAA TTGAAAA TGAAAAG GAAAAGA AAAAGAT AAAGATG AAGATGG AGATGGA GATGGAG ATGGAGA TGGAGAA GGAGAAT GAGAATT AGAATTG GAATTGG AATTGGG ATTGGGT TTGGGTT TGGGTTC GGGTTCC GGTTCCG GTTCCGG TTCCGGA TCCGGAC CCGGACC CGGACCC GGACCCA GACCCAA ACCCAAT CCCAATT CCAATTT CAATTTT AATTTTA ATTTTAC TTTTACC TTTACCC TTACCCT TACCCTA ACCCTAC CCCTACA CCTACAC CTACACC TACACCC ACACCCT CACCCTA ACCCTAT CCCTATA CCTATAA CTATAAG TATAAGA ATAAGAG TAAGAGA AAGAGAT AGAGATG GAGATGT AGATGTT GATGTTC ATGTTCT TGTTCTA GTTCTAC TTCTACT TCTACTT CTACTTT TACTTTC ACTTTCA CTTTCAG TTTCAGG TTCAGGT TCAGGTC CAGGTCT AGGTCTC GGTCTCT GTCTCTT TCTCTTT CTCTTTT TCTTTTT CTTTTTA TTTTTAT TTTTATT TTTATTG TTATTGT TATTGTT ATTGTTT TTGTTTC TGTTTCT GTTTCTG TTTCTGG TTCTGGA TCTGGAT CTGGATG TGGATGT GGATGTA GATGTAG ATGTAGT TGTAGTT GTAGTTT TAGTTTG AGTTTGG GTTTGGT TTTGGTG TTGGTGC TGGTGCC GGTGCCT GTGCCTA TGCCTAG GCCTAGC CCTAGCT CTAGCTT TAGCTTT AGCTTTG GCTTTGA CTTTGAC TTTGACC TTGACCT TGACCTC GACCTCA ACCTCAT CCTCATG CTCATGA TCATGAC CATGACC ATGACCC TGACCCC GACCCCA ACCCCAA CCCCAAA CCCAAAC CCAAACA CAAACAG AAACAGG AACAGGC ACAGGCT CAGGCTT AGGCTTT GGCTTTT GCTTTTG CTTTTGC TTTTGCT TTTGCTT TTGCTTT TGCTTTA GCTTTAG CTTTAGG TTTAGGG TTAGGGT TAGGGTT AGGGTTC GGGTTCC GGTTCCC GTTCCCT TTCCCTC TCCCTCC CCCTCCC CCTCCCG CTCCCGG TCCCGGG CCCGGGG CCGGGGG CGGGGGG GGGGGGG GGGGGGG GGGGGGG GGGGGGG GGGGGGG GGGGGGG GGGGGGA GGGGGAA GGGGAAG GGGAAGC GGAAGCT GAAGCTG AAGCTGG AGCTGGA GCTGGAC CTGGACT TGGACTG GGACTGC GACTGCA ACTGCAG CTGCAGC TGCAGCT GCAGCTG CAGCTGG AGCTGGT GCTGGTC CTGGTCC TGGTCCA GGTCCAT GTCCATA TCCATAT CCATATT CATATTT ATATTTG TATTTGG ATTTGGT TTTGGTT TTGGTTA TGGTTAG GGTTAGC GTTAGCA TTAGCAG TAGCAGG AGCAGGA GCAGGAG CAGGAGT AGGAGTC GGAGTCC GAGTCCC AGTCCCA GTCCCAG TCCCAGC CCCAGCG CCAGCGG CAGCGGA AGCGGAC GCGGACC CGGACCC GGACCCC GACCCCT ACCCCTC CCCCTCG CCCTCGG CCTCGGA CTCGGAG TCGGAGG CGGAGGA GGAGGAG GAGGAGG AGGAGGT GGAGGTC GAGGTCC AGGTCCC GGTCCCC GTCCCCT TCCCCTA CCCCTAG CCCTAGG CCTAGGA CTAGGAG TAGGAGG AGGAGGG GGAGGGC GAGGGCT AGGGCTA GGGCTAG GGCTAGG GCTAGGG CTAGGGC TAGGGCT AGGGCTA GGGCTAG GGCTAGG GCTAGGC CTAGGCT TAGGCTA AGGCTAG GGCTAGT GCTAGTG CTAGTGG TAGTGGA AGTGGAA GTGGAAT TGGAATT GGAATTT GAATTTT AATTTTT ATTTTTT TTTTTTT TTTTTTT TTTTTTT TTTTTTT TTTTTTC TTTTTCA TTTTCAG TTTCAGT TTCAGTG TCAGTGA CAGTGAC AGTGACC GTGACCG TGACCGG GACCGGC ACCGGCA CCGGCAC CGGCACA GGCACAA GCACAAA CACAAAG ACAAAGC CAAAGCG AAAGCGC AAGCGCC AGCGCCG GCGCCGG CGCCGGA GCCGGAA CCGGAAA CGGAAAA GGAAAAT GAAAATT AAAATTT AAATTTT AATTTTT ATTTTTA TTTTTAG TTTTAGG TTTAGGA TTAGGAC TAGGACC AGGACCC GGACCCC GACCCCC ACCCCCC CCCCCCA CCCCCAA CCCCAAA CCCAAAA CCAAAAT CAAAATG AAAATGG AAATGGC AATGGCC ATGGCCA TGGCCAA GGCCAAA GCCAAAA CCAAAAC CAAAACT AAAACTG AAACTGA AACTGAC ACTGACC CTGACCA TGACCAT GACCATT ACCATTT CCATTTT CATTTTG ATTTTGG TTTTGGC TTTGGCT TTGGCTA TGGCTAT GGCTATT GCTATTT CTATTTT TATTTTT ATTTTTT TTTTTTG TTTTTGG TTTTGGA TTTGGAT TTGGATT TGGATTT GGATTTT GATTTTT ATTTTTT TTTTTTT TTTTTTT TTTTTTT TTTTTTG TTTTTGG TTTTGGG TTTGGGA TTGGGAA TGGGAAG GGGAAGT GGAAGTT GAAGTTA AAGTTAA AGTTAAT GTTAATC TTAATCA TAATCAG AATCAGC ATCAGCC TCAGCCA CAGCCAA AGCCAAA GCCAAAA CCAAAAA CAAAAAA AAAAAAA AAAAAAC AAAAACC AAAACCC AAACCCA AACCCAA ACCCAAT CCCAATT CCAATTG CAATTGA AATTGAA ATTGAAA TTGAAAC TGAAACG GAAACGC AAACGCC AACGCCA ACGCCAT CGCCATT GCCATTT CCATTTC CATTTCC ATTTCCA TTTCCAC TTCCACC TCCACCT CCACCTT CACCTTG ACCTTGG CCTTGGT CTTGGTG TTGGTGC TGGTGCG GGTGCGC GTGCGCA TGCGCAG GCGCAGC CGCAGCG GCAGCGT CAGCGTT AGCGTTG GCGTTGG CGTTGGA GTTGGAG TTGGAGG TGGAGGG GGAGGGA GAGGGAA AGGGAAA GGGAAAA GGAAAAT GAAAATG AAAATGT AAATGTT AATGTTT ATGTTTT TGTTTTC GTTTTCC TTTTCCA TTTCCAG TTCCAGC TCCAGCT CCAGCTG CAGCTGG AGCTGGA GCTGGAG CTGGAGG TGGAGGG GGAGGGA GAGGGAA AGGGAAC GGGAACC GGAACCC GAACCCC AACCCCC ACCCCCC CCCCCCC CCCCCCC CCCCCCC CCCCCCC CCCCCCC CCCCCCC CCCCCCC CCCCCCG CCCCCGG CCCCGGG CCCGGGA CCGGGAG CGGGAGA GGGAGAG GGAGAGG GAGAGGG AGAGGGG GAGGGGG AGGGGGT GGGGGTC GGGGTCT GGGTCTA GGTCTAG GTCTAGC TCTAGCC CTAGCCA TAGCCAG AGCCAGT GCCAGTC CCAGTCC CAGTCCA AGTCCAA GTCCAAT TCCAATT CCAATTT CAATTTT AATTTTT ATTTTTC TTTTTCC TTTTCCA TTTCCAG TTCCAGT TCCAGTA CCAGTAT CAGTATT AGTATTT GTATTTA TATTTAG ATTTAGC TTTAGCA TTAGCAA TAGCAAA AGCAAAA GCAAAAT CAAAATG AAAATGG AAATGGC AATGGCT ATGGCTA TGGCTAG GGCTAGC GCTAGCC CTAGCCA TAGCCAA AGCCAAC GCCAACG CCAACGG CAACGGA AACGGAC ACGGACT CGGACTA GGACTAA GACTAAC ACTAACC CTAACCC TAACCCC AACCCCG ACCCCGG CCCCGGG CCCGGGT CCGGGTC CGGGTCC GGGTCCT GGTCCTT GTCCTTA TCCTTAA CCTTAAG CTTAAGC TTAAGCA TAAGCAA AAGCAAT AGCAATG GCAATGG CAATGGC AATGGCC ATGGCCT TGGCCTG GGCCTGT GCCTGTC CCTGTCT CTGTCTC TGTCTCA GTCTCAG TCTCAGA CTCAGAA TCAGAAG CAGAAGC AGAAGCT GAAGCTT AAGCTTC AGCTTCT GCTTCTG CTTCTGC TTCTGCC TCTGCCA CTGCCAA TGCCAAA GCCAAAT CCAAATT CAAATTT AAATTTT AATTTTT ATTTTTC TTTTTCG TTTTCGA TTTCGAG TTCGAGA TCGAGAT CGAGATG GAGATGA AGATGAA GATGAAA ATGAAAA TGAAAAC GAAAACC AAAACCT AAACCTA AACCTAC ACCTACC CCTACCT CTACCTC TACCTCA ACCTCAT CCTCATA CTCATAA TCATAAA CATAAAA ATAAAAT TAAAATA AAAATAC AAATACA AATACAC ATACACA TACACAA ACACAAG CACAAGA ACAAGAA CAAGAAA AAGAAAA AGAAAAC GAAAACA AAAACAT AAACATT AACATTT ACATTTC CATTTCT ATTTCTC TTTCTCA TTCTCAG TCTCAGA CTCAGAT TCAGATT CAGATTG AGATTGG GATTGGT ATTGGTA TTGGTAA TGGTAAT GGTAATC GTAATCT TAATCTT AATCTTT ATCTTTA TCTTTAA CTTTAAA TTTAAAT TTAAATG TAAATGG AAATGGT AATGGTT ATGGTTG TGGTTGG GGTTGGT GTTGGTT TTGGTTG TGGTTGG GGTTGGA GTTGGAG TTGGAGC TGGAGCC GGAGCCG GAGCCGG AGCCGGG GCCGGGA CCGGGAG CGGGAGG GGGAGGC GGAGGCA GAGGCAT AGGCATA GGCATAT GCATATT CATATTT ATATTTT TATTTTT ATTTTTT TTTTTTT TTTTTTT TTTTTTG TTTTTGA TTTTGAG TTTGAGT TTGAGTT TGAGTTA GAGTTAA AGTTAAA GTTAAAA TTAAAAA TAAAAAC AAAAACT AAAACTG AAACTGG AACTGGT ACTGGTG CTGGTGA TGGTGAT GGTGATG GTGATGT TGATGTC GATGTCT ATGTCTC TGTCTCA GTCTCAC TCTCACA CTCACAG TCACAGG CACAGGG ACAGGGG CAGGGGA AGGGGAG GGGGAGG GGGAGGG GGAGGGC GAGGGCC AGGGCCG GGGCCGC GGCCGCC GCCGCCT CCGCCTA CGCCTAA GCCTAAC CCTAACG CTAACGT TAACGTT AACGTTG ACGTTGT CGTTGTT GTTGTTT TTGTTTT TGTTTTT GTTTTTT TTTTTTC TTTTTCC TTTTCCC TTTCCCG TTCCCGA TCCCGAC CCCGACG CCGACGT CGACGTT GACGTTT ACGTTTT CGTTTTT GTTTTTA TTTTTAA TTTTAAA TTTAAAG TTAAAGG TAAAGGT AAAGGTT AAGGTTT AGGTTTT GGTTTTT GTTTTTT TTTTTTT TTTTTTC TTTTTCC TTTTCCC TTTCCCC TTCCCCT TCCCCTT CCCCTTC CCCTTCA CCTTCAT CTTCATC TTCATCT TCATCTC CATCTCT ATCTCTC TCTCTCC CTCTCCC TCTCCCT CTCCCTG TCCCTGT CCCTGTT CCTGTTG CTGTTGT TGTTGTG GTTGTGG TTGTGGG TGTGGGG GTGGGGG TGGGGGG GGGGGGG GGGGGGG GGGGGGG GGGGGGG GGGGGGT GGGGGTC GGGGTCC GGGTCCT GGTCCTG GTCCTGC TCCTGCA CCTGCAA CTGCAAA TGCAAAA GCAAAAT CAAAATT AAAATTT AAATTTA AATTTAG ATTTAGT TTTAGTT TTAGTTG TAGTTGG AGTTGGG GTTGGGT TTGGGTG TGGGTGG GGGTGGG GGTGGGG GTGGGGG TGGGGGT GGGGGTG GGGGTGA GGGTGAT GGTGATC GTGATCA TGATCAG GATCAGC ATCAGCG TCAGCGC CAGCGCC AGCGCCC GCGCCCT CGCCCTC GCCCTCT CCCTCTT CCTCTTC CTCTTCT TCTTCTT CTTCTTG TTCTTGG TCTTGGA CTTGGAA TTGGAAA TGGAAAT GGAAATA GAAATAT AAATATT AATATTG ATATTGT TATTGTC ATTGTCT TTGTCTG TGTCTGA GTCTGAA TCTGAAA CTGAAAC TGAAACT GAAACTG AAACTGT AACTGTG ACTGTGG CTGTGGT TGTGGTT GTGGTTG TGGTTGG GGTTGGG GTTGGGC TTGGGCT TGGGCTG GGGCTGG GGCTGGT GCTGGTT CTGGTTA TGGTTAT GGTTATT GTTATTG TTATTGA TATTGAA ATTGAAA TTGAAAA TGAAAAT GAAAATC AAAATCC AAATCCC AATCCCT ATCCCTG TCCCTGA CCCTGAC CCTGACA CTGACAT TGACATA GACATAA ACATAAC CATAACG ATAACGA TAACGAT AACGATA ACGATAG CGATAGC GATAGCA ATAGCAG TAGCAGC AGCAGCC GCAGCCC CAGCCCC AGCCCCG GCCCCGT CCCCGTT CCCGTTT CCGTTTC CGTTTCT GTTTCTT TTTCTTA TTCTTAT TCTTATG CTTATGT TTATGTA TATGTAG ATGTAGC TGTAGCG GTAGCGG TAGCGGG AGCGGGG GCGGGGG CGGGGGG GGGGGGG GGGGGGG GGGGGGG GGGGGGG GGGGGGG GGGGGGT GGGGGTA GGGGTAT GGGTATA GGTATAT GTATATT TATATTG ATATTGC TATTGCT ATTGCTG TTGCTGT TGCTGTG GCTGTGG CTGTGGT TGTGGTT GTGGTTT TGGTTTT GGTTTTC GTTTTCC TTTTCCC TTTCCCG TTCCCGC TCCCGCA CCCGCAG CCGCAG CGCAG GCAG CAG AG\n",
      "GTGCGTTGCCTGTGTGACCCCAATTCCAGATTTTGGGAATGCCAACGTAATGCCAACATGGGAAAAAATCACCCTTGAAAAGATGGAGAATTGGGTTCCGGACCCAATTTTACCCTACACCCTATAAGAGATGTTCTACTTTCAGGTCTCTTTTTATTGTTTCTGGATGTAGTTTGGTGCCTAGCTTTGACCTCATGACCCCAAACAGGCTTTTGCTTTAGGGTTCCCTCCCGGGGGGGGGGGGAAGCTGGACTGCAGCTGGTCCATATTTGGTTAGCAGGAGTCCCAGCGGACCCCTCGGAGGAGGTCCCCTAGGAGGGCTAGGGCTAGGCTAGTGGAATTTTTTTTTTCAGTGACCGGCACAAAGCGCCGGAAAATTTTTAGGACCCCCCAAAATGGCCAAAACTGACCATTTTGGCTATTTTTTGGATTTTTTTTTGGGAAGTTAATCAGCCAAAAAAACCCAATTGAAACGCCATTTCCACCTTGGTGCGCAGCGTTGGAGGGAAAATGTTTTCCAGCTGGAGGGAACCCCCCCCCCCCCGGGAGAGGGGGTCTAGCCAGTCCAATTTTTCCAGTATTTAGCAAAATGGCTAGCCAACGGACTAACCCCGGGTCCTTAAGCAATGGCCTGTCTCAGAAGCTTCTGCCAAATTTTTCGAGATGAAAACCTACCTCATAAAATACACAAGAAAACATTTCTCAGATTGGTAATCTTTAAATGGTTGGTTGGAGCCGGGAGGCATATTTTTTTTGAGTTAAAAACTGGTGATGTCTCACAGGGGAGGGCCGCCTAACGTTGTTTTTTCCCGACGTTTTTAAAGGTTTTTTTCCCCTTCATCTCTCCCTGTTGTGGGGGGGGGGTCCTGCAAAATTTAGTTGGGTGGGGGTGATCAGCGCCCTCTTCTTGGAAATATTGTCTGAAACTGTGGTTGGGCTGGTTATTGAAAATCCCTGACATAACGATAGCAGCCCCGTTTCTTATGTAGCGGGGGGGGGGGTATATTGCTGTGGTTTTCCCGCAG\n",
      "  (0, 2932)\t0.021330845729263602\n",
      "  (0, 6582)\t0.02292742342170392\n",
      "  (0, 13392)\t0.03318034500354597\n",
      "  (0, 22834)\t0.04185726968347818\n",
      "  (0, 24754)\t0.05263098167920384\n",
      "  (0, 25242)\t0.029818413640518147\n",
      "  (0, 25370)\t0.02431678396559188\n",
      "  (0, 11721)\t0.032211879965331196\n",
      "  (0, 22413)\t0.029926467231096873\n",
      "  (0, 25213)\t0.02493603046080447\n",
      "  (0, 25361)\t0.024433903977605448\n",
      "  (0, 11718)\t0.031238721424361925\n",
      "  (0, 14676)\t0.0340044887840251\n",
      "  (0, 3663)\t0.03462005594721776\n",
      "  (0, 6766)\t0.03493996627466698\n",
      "  (0, 21172)\t0.041506412668998446\n",
      "  (0, 16601)\t0.04274945137446749\n",
      "  (0, 4130)\t0.04193570822303765\n",
      "  (0, 6890)\t0.03677834491938706\n",
      "  (0, 13471)\t0.040044203716289944\n",
      "  (0, 3367)\t0.04388052319735298\n",
      "  (0, 12575)\t0.044030866038939145\n",
      "  (0, 14894)\t0.03930459395492242\n",
      "  (0, 23212)\t0.03897886321205578\n",
      "  (0, 17111)\t0.04223753601997988\n",
      "  :\t:\n",
      "  (1910947, 5934)\t0.08209461231871115\n",
      "  (1910947, 7352)\t0.07745500903904882\n",
      "  (1910947, 13585)\t0.04508598978917829\n",
      "  (1910947, 15147)\t0.024483712093679392\n",
      "  (1910947, 23277)\t0.026233303492131956\n",
      "  (1910947, 25284)\t0.027809051115460493\n",
      "  (1910947, 11699)\t0.03333796732700866\n",
      "  (1910947, 8822)\t0.01500479671410973\n",
      "  (1910947, 2223)\t0.01749573024998915\n",
      "  (1910947, 1483)\t0.015542241059401161\n",
      "  (1910947, 9524)\t0.019536928756736575\n",
      "  (1910947, 5844)\t0.008879047951391652\n",
      "  (1910947, 12107)\t0.01430082216710343\n",
      "  (1910947, 14778)\t0.015557673345266062\n",
      "  (1910947, 13534)\t0.01911497470075327\n",
      "  (1910947, 16757)\t0.022099258908947046\n",
      "  (1910947, 9806)\t0.016677503514432562\n",
      "  (1910947, 23812)\t0.33446796741924967\n",
      "  (1910947, 5154)\t0.01902615308461707\n",
      "  (1910947, 12489)\t0.019061654870878287\n",
      "  (1910947, 22960)\t0.016252795090123916\n",
      "  (1910947, 24787)\t0.017170214240800848\n",
      "  (1910947, 23297)\t0.016338239495849463\n",
      "  (1910947, 22694)\t0.019211973517640007\n",
      "  (1910947, 24838)\t0.014253998463523971\n"
     ]
    }
   ],
   "source": [
    "###VISUALISATION OF WHAT IS HAPPENNING\n",
    "started = time.time()\n",
    "\n",
    "sequences_cut, split_seqs, seq4, vectorizer = kmeans.preprocess(0, 7, sequences)\n",
    "\n",
    "print(time.time()-started, \"seconds\")\n",
    "\n",
    "print(split_seqs[1])\n",
    "print(sequences_cut[1])\n",
    "print(seq4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t0.46979138557992045\n",
      "  (0, 2)\t0.5802858236844359\n",
      "  (0, 6)\t0.38408524091481483\n",
      "  (0, 3)\t0.38408524091481483\n",
      "  (0, 8)\t0.38408524091481483\n",
      "  (1, 5)\t0.5386476208856763\n",
      "  (1, 1)\t0.6876235979836938\n",
      "  (1, 6)\t0.281088674033753\n",
      "  (1, 3)\t0.281088674033753\n",
      "  (1, 8)\t0.281088674033753\n",
      "  (2, 4)\t0.511848512707169\n",
      "  (2, 7)\t0.511848512707169\n",
      "  (2, 0)\t0.511848512707169\n",
      "  (2, 6)\t0.267103787642168\n",
      "  (2, 3)\t0.267103787642168\n",
      "  (2, 8)\t0.267103787642168\n",
      "  (3, 1)\t0.46979138557992045\n",
      "  (3, 2)\t0.5802858236844359\n",
      "  (3, 6)\t0.38408524091481483\n",
      "  (3, 3)\t0.38408524091481483\n",
      "  (3, 8)\t0.38408524091481483\n",
      "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']\n",
      "0 document 0.46979138557992045\n",
      "0 first 0.5802858236844359\n",
      "0 is 0.38408524091481483\n",
      "0 the 0.38408524091481483\n",
      "0 this 0.38408524091481483\n",
      "1 document 0.6876235979836938\n",
      "1 is 0.281088674033753\n",
      "1 second 0.5386476208856763\n",
      "1 the 0.281088674033753\n",
      "1 this 0.281088674033753\n",
      "2 and 0.511848512707169\n",
      "2 is 0.267103787642168\n",
      "2 one 0.511848512707169\n",
      "2 the 0.267103787642168\n",
      "2 third 0.511848512707169\n",
      "2 this 0.267103787642168\n",
      "3 document 0.46979138557992045\n",
      "3 first 0.5802858236844359\n",
      "3 is 0.38408524091481483\n",
      "3 the 0.38408524091481483\n",
      "3 this 0.38408524091481483\n"
     ]
    }
   ],
   "source": [
    "###VISUALISATION OF LIBRARY WORKING\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = [\n",
    "     'This is the first document.',\n",
    "     'This document is the second document.',\n",
    "     'And this is the third one.',\n",
    "     'Is this the first document?',\n",
    "]\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X)\n",
    "print(vectorizer.get_feature_names())\n",
    "for s in range(4):\n",
    "    for ind, word in enumerate(vectorizer.get_feature_names()):\n",
    "         if X[s, ind] != 0:\n",
    "             print(s, word, X[s, ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1910948x506 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 369977091 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4x9 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AA', 'AAA', 'AAAA', 'AAAC', 'AAAG', 'AAAN', 'AAAT', 'AAC', 'AACA', 'AACC', 'AACG', 'AACN', 'AACT', 'AAG', 'AAGA', 'AAGC', 'AAGG', 'AAGN', 'AAGT', 'AANN', 'AAT', 'AATA', 'AATC', 'AATG', 'AATN', 'AATT', 'AC', 'ACA', 'ACAA', 'ACAC', 'ACAG', 'ACAN', 'ACAT', 'ACC', 'ACCA', 'ACCC', 'ACCG', 'ACCN', 'ACCT', 'ACG', 'ACGA', 'ACGC', 'ACGG', 'ACGN', 'ACGT', 'ACNN', 'ACT', 'ACTA', 'ACTC', 'ACTG', 'ACTN', 'ACTT', 'AG', 'AGA', 'AGAA', 'AGAC', 'AGAG', 'AGAN', 'AGAT', 'AGC', 'AGCA', 'AGCC', 'AGCG', 'AGCN', 'AGCT', 'AGG', 'AGGA', 'AGGC', 'AGGG', 'AGGN', 'AGGT', 'AGNN', 'AGT', 'AGTA', 'AGTC', 'AGTG', 'AGTN', 'AGTT', 'ANNN', 'AT', 'ATA', 'ATAA', 'ATAC', 'ATAG', 'ATAN', 'ATAT', 'ATC', 'ATCA', 'ATCC', 'ATCG', 'ATCN', 'ATCT', 'ATG', 'ATGA', 'ATGC', 'ATGG', 'ATGN', 'ATGT', 'ATNN', 'ATT', 'ATTA', 'ATTC', 'ATTG', 'ATTN', 'ATTT', 'CA', 'CAA', 'CAAA', 'CAAC', 'CAAG', 'CAAN', 'CAAT', 'CAC', 'CACA', 'CACC', 'CACG', 'CACN', 'CACT', 'CAG', 'CAGA', 'CAGC', 'CAGG', 'CAGN', 'CAGT', 'CANN', 'CAT', 'CATA', 'CATC', 'CATG', 'CATN', 'CATT', 'CC', 'CCA', 'CCAA', 'CCAC', 'CCAG', 'CCAN', 'CCAT', 'CCC', 'CCCA', 'CCCC', 'CCCG', 'CCCN', 'CCCT', 'CCG', 'CCGA', 'CCGC', 'CCGG', 'CCGN', 'CCGT', 'CCNN', 'CCT', 'CCTA', 'CCTC', 'CCTG', 'CCTN', 'CCTT', 'CG', 'CGA', 'CGAA', 'CGAC', 'CGAG', 'CGAN', 'CGAT', 'CGC', 'CGCA', 'CGCC', 'CGCG', 'CGCN', 'CGCT', 'CGG', 'CGGA', 'CGGC', 'CGGG', 'CGGN', 'CGGT', 'CGNN', 'CGT', 'CGTA', 'CGTC', 'CGTG', 'CGTN', 'CGTT', 'CNNN', 'CT', 'CTA', 'CTAA', 'CTAC', 'CTAG', 'CTAN', 'CTAT', 'CTC', 'CTCA', 'CTCC', 'CTCG', 'CTCN', 'CTCT', 'CTG', 'CTGA', 'CTGC', 'CTGG', 'CTGN', 'CTGT', 'CTNN', 'CTT', 'CTTA', 'CTTC', 'CTTG', 'CTTN', 'CTTT', 'GA', 'GAA', 'GAAA', 'GAAC', 'GAAG', 'GAAN', 'GAAT', 'GAC', 'GACA', 'GACC', 'GACG', 'GACN', 'GACT', 'GAG', 'GAGA', 'GAGC', 'GAGG', 'GAGN', 'GAGT', 'GANN', 'GAT', 'GATA', 'GATC', 'GATG', 'GATN', 'GATT', 'GC', 'GCA', 'GCAA', 'GCAC', 'GCAG', 'GCAN', 'GCAT', 'GCC', 'GCCA', 'GCCC', 'GCCG', 'GCCN', 'GCCT', 'GCG', 'GCGA', 'GCGC', 'GCGG', 'GCGN', 'GCGT', 'GCNN', 'GCT', 'GCTA', 'GCTC', 'GCTG', 'GCTN', 'GCTT', 'GG', 'GGA', 'GGAA', 'GGAC', 'GGAG', 'GGAN', 'GGAT', 'GGC', 'GGCA', 'GGCC', 'GGCG', 'GGCN', 'GGCT', 'GGG', 'GGGA', 'GGGC', 'GGGG', 'GGGN', 'GGGT', 'GGNN', 'GGT', 'GGTA', 'GGTC', 'GGTG', 'GGTN', 'GGTT', 'GNNN', 'GT', 'GTA', 'GTAA', 'GTAC', 'GTAG', 'GTAN', 'GTAT', 'GTC', 'GTCA', 'GTCC', 'GTCG', 'GTCN', 'GTCT', 'GTG', 'GTGA', 'GTGC', 'GTGG', 'GTGN', 'GTGT', 'GTNN', 'GTT', 'GTTA', 'GTTC', 'GTTG', 'GTTN', 'GTTT', 'NAAA', 'NAAC', 'NAAG', 'NAAT', 'NACA', 'NACC', 'NACG', 'NACT', 'NAG', 'NAGA', 'NAGC', 'NAGG', 'NAGT', 'NATA', 'NATC', 'NATG', 'NATT', 'NCAA', 'NCAC', 'NCAG', 'NCAT', 'NCCA', 'NCCC', 'NCCG', 'NCCT', 'NCGA', 'NCGC', 'NCGG', 'NCGT', 'NCTA', 'NCTC', 'NCTG', 'NCTT', 'NGAA', 'NGAC', 'NGAG', 'NGAT', 'NGCA', 'NGCC', 'NGCG', 'NGCT', 'NGGA', 'NGGC', 'NGGG', 'NGGT', 'NGTA', 'NGTC', 'NGTG', 'NGTT', 'NNAA', 'NNAC', 'NNAG', 'NNAT', 'NNCA', 'NNCC', 'NNCG', 'NNCT', 'NNGA', 'NNGC', 'NNGG', 'NNGT', 'NNNA', 'NNNC', 'NNNG', 'NNNN', 'NNNT', 'NNTA', 'NNTC', 'NNTG', 'NNTT', 'NTAA', 'NTAC', 'NTAG', 'NTAT', 'NTCA', 'NTCC', 'NTCG', 'NTCT', 'NTGA', 'NTGC', 'NTGG', 'NTGT', 'NTTA', 'NTTC', 'NTTG', 'NTTT', 'TA', 'TAA', 'TAAA', 'TAAC', 'TAAG', 'TAAN', 'TAAT', 'TAC', 'TACA', 'TACC', 'TACG', 'TACN', 'TACT', 'TAG', 'TAGA', 'TAGC', 'TAGG', 'TAGN', 'TAGT', 'TANN', 'TAT', 'TATA', 'TATC', 'TATG', 'TATN', 'TATT', 'TC', 'TCA', 'TCAA', 'TCAC', 'TCAG', 'TCAN', 'TCAT', 'TCC', 'TCCA', 'TCCC', 'TCCG', 'TCCN', 'TCCT', 'TCG', 'TCGA', 'TCGC', 'TCGG', 'TCGN', 'TCGT', 'TCNN', 'TCT', 'TCTA', 'TCTC', 'TCTG', 'TCTN', 'TCTT', 'TG', 'TGA', 'TGAA', 'TGAC', 'TGAG', 'TGAN', 'TGAT', 'TGC', 'TGCA', 'TGCC', 'TGCG', 'TGCN', 'TGCT', 'TGG', 'TGGA', 'TGGC', 'TGGG', 'TGGN', 'TGGT', 'TGNN', 'TGT', 'TGTA', 'TGTC', 'TGTG', 'TGTN', 'TGTT', 'TNNN', 'TT', 'TTA', 'TTAA', 'TTAC', 'TTAG', 'TTAN', 'TTAT', 'TTC', 'TTCA', 'TTCC', 'TTCG', 'TTCN', 'TTCT', 'TTG', 'TTGA', 'TTGC', 'TTGG', 'TTGN', 'TTGT', 'TTNN', 'TTT', 'TTTA', 'TTTC', 'TTTG', 'TTTN', 'TTTT']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
