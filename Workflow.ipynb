{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filter_junctions\n",
    "import intron_comparison\n",
    "import intron_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNA-seq data has been aligned to *Euglena longa* genome with the help of two programs - HISAT2 and STAR. Then the introns were extracted using RegTools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's have a look at basic statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program:  hisat\n",
      "Number of introns: 197019\n",
      "Mean support: 59.74485709500099\n",
      "Median support: 9\n",
      "\n",
      "\n",
      "Program:  star\n",
      "Number of introns: 218640\n",
      "Mean support: 44.03127515550677\n",
      "Median support: 6.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "programs = ['hisat', 'star']\n",
    "for program in programs:\n",
    "    print('Program: ', program)\n",
    "    file_in = f'data/junctions_{program}.bed'\n",
    "    file_out = f'data/good_junctions_{program}.bed'\n",
    "    filter_junctions.junctions_to_introns(file_in, file_out)\n",
    "    filter_junctions.intron_stats(file_out)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Because of errors in data and in alignments, there are multiple introns overlapping. We want to choose only one introns in every position that has the strongest support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program:  hisat\n",
      "Number of introns: 121603\n",
      "Mean support: 87.48627912140326\n",
      "Median support: 17\n",
      "Mean share of the best intron:  0.8219934856545911\n",
      "Share of best introns in all:  0.48993422067625914\n",
      "Mean support of the best intron:  96.79754611317155\n",
      "\n",
      "\n",
      "Program:  star\n",
      "Number of introns: 121693\n",
      "Mean support: 72.18693762172023\n",
      "Median support: 16\n",
      "Mean share of the best intron:  0.7372594956871039\n",
      "Share of best introns in all:  0.4522015066378948\n",
      "Mean support of the best intron:  79.10888876106267\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for program in programs:\n",
    "    print('Program: ', program)\n",
    "    cutoff = 1 # First we look at all the best introns\n",
    "\n",
    "    file_in = f'data/good_junctions_{program}.bed'\n",
    "    file_out = f'data/best_introns_{program}{cutoff}.bed'\n",
    "    all_i, best_i = filter_junctions.choose_best_introns(file_in, file_out, cutoff)\n",
    "    filter_junctions.intron_stats(file_out)\n",
    "\n",
    "    filter_junctions.compare_best_introns(all_i, best_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All the stats for HISAT are better, so this is the alignment chosen for the following analyses.\n",
    "\n",
    "### After trying different cutoffs, threshold 50 was chosen, leaving quite a big set of comperatively reliable introns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of introns: 26247\n",
      "Mean support: 349.5671505314893\n",
      "Median support: 97\n",
      "Mean share of the best intron:  0.9131872756561444\n",
      "Share of best introns in all:  0.6623805780914107\n",
      "Mean support of the best intron:  448.4654246199566\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cutoff = 50\n",
    "file_in = f'data/good_junctions_hisat.bed'\n",
    "file_out = f'data/best_introns_hisat{cutoff}.bed'\n",
    "\n",
    "all_i, best_i = filter_junctions.choose_best_introns(file_in, file_out, cutoff)\n",
    "filter_junctions.intron_stats(file_out)\n",
    "\n",
    "filter_junctions.compare_best_introns(all_i, best_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introns were also extracted from transcripts, so we compare the two sets and only choose the introns that are idenctical in both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All my introns:  26247\n",
      "n of pairs:  31975\n",
      "no match:  2627\n",
      "exact match:  22036\n",
      "one side matching:  1149\n",
      "length difference distribution:\n",
      "[(0, 0), (1, 291), (2, 81), (3, 113), (4, 29), (5, 12), (6, 9), (7, 4), (8, 4), (9, 2)]\n"
     ]
    }
   ],
   "source": [
    "intron_comparison.extract_introns_from_gtf('data/longa_stringtie_strand_informed.gtf', 'data/other_introns.bed')\n",
    "other_introns = intron_comparison.intron_dict('data/other_introns.bed')\n",
    "\n",
    "file = 'data/best_introns_hisat50.bed'\n",
    "file_out = 'data/introns_hisat_50_cross_checked.bed'\n",
    "exact_match, one_side_match, diff_lengths = intron_comparison.compare_introns(file, other_introns, file_out)\n",
    "\n",
    "print('exact match: ', len(exact_match))\n",
    "# print(exact_match)\n",
    "\n",
    "print('one side matching: ', len(one_side_match))\n",
    "# print(one_side_match)\n",
    "\n",
    "print('length difference distribution:')\n",
    "print([(x, diff_lengths.count(x)) for x in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing .bed files for extracting the sequences with additional margin (intron sequences + a bit of surrounding exons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_junctions.introns_for_seq('data/introns_hisat_50_cross_checked.bed', 'data/best_introns_hisat_50+0.bed', 0)\n",
    "filter_junctions.introns_for_seq('data/introns_hisat_50_cross_checked.bed', 'data/best_introns_hisat_50+3.bed', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After extracting intron sequences they are classified as: conventional if they have the canonical AG|GT junctions, confirmed nonconventional if they can form secondary structure in specific position or unconrfirmed nonconventional otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv stats: \n",
      "Number of introns:  12815\n",
      "Mean length:  878.709090909091\n",
      "Mean gc:  0.4931897550119602\n",
      "Tetranucleotides: \n",
      "[('TTTT', 146648), ('GGGG', 145918), ('AAAA', 143549), ('CCCC', 142800), ('TGTG', 135543), ('CACA', 135406), ('TTTG', 108378), ('CAAA', 108045), ('ACAC', 104849), ('GTGT', 104524)]\n",
      "\n",
      "nonconv stats: \n",
      "Number of introns:  7602\n",
      "Mean length:  643.9623783214944\n",
      "Mean gc:  0.5143102063917632\n",
      "Tetranucleotides: \n",
      "[('CCCC', 67815), ('GGGG', 63082), ('TTTT', 62311), ('TGTG', 57242), ('CACA', 55869), ('AAAA', 55338), ('TTTG', 46370), ('CAAA', 43809), ('GTGT', 43648), ('ACAC', 42479)]\n",
      "\n",
      "rest: \n",
      "Number of introns:  5172\n",
      "Mean length:  654.6084686774942\n",
      "Mean gc:  0.5116076688333633\n",
      "Tetranucleotides: \n",
      "[('GGGG', 47196), ('AAAA', 43535), ('CCCC', 42241), ('TGTG', 39809), ('TTTT', 38026), ('CACA', 37854), ('CAAA', 32501), ('TTTG', 30655), ('GTGT', 30050), ('ACAC', 28744)]\n"
     ]
    }
   ],
   "source": [
    "introns_seq_file = 'data/good_introns50+3.fasta' #file with the sequences\n",
    "\n",
    "introns = intron_sequences.file_to_seq_introns(introns_seq_file, 3)\n",
    "conv = []\n",
    "non_conv = []\n",
    "rest = []\n",
    "for intron in introns:\n",
    "    intron.movable_boundary()\n",
    "    if intron.check_conventional():\n",
    "        conv.append(intron)\n",
    "    elif intron.check_unconventional():\n",
    "        non_conv.append(intron)\n",
    "    else:\n",
    "        rest.append(intron)\n",
    "\n",
    "print('conv stats: ')\n",
    "_ = intron_sequences.seq_statistics(conv)\n",
    "\n",
    "print('\\nnonconv stats: ')\n",
    "_ = intron_sequences.seq_statistics(non_conv)\n",
    "\n",
    "print('\\nrest: ')\n",
    "_ = intron_sequences.seq_statistics(rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
